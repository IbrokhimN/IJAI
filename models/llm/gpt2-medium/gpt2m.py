import os
import wikipediaapi
import torch
from transformers import (
    GPT2LMHeadModel,
    GPT2Tokenizer,
    Trainer,
    TrainingArguments,
    TextDataset,
    DataCollatorForLanguageModeling,
)

# === 0. –¢–µ–º—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ===
articles = [
    "Python",  # –≤–æ–∑—å–º—ë—Ç –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ Python
    "–§—Ä–∏–¥—Ä–∏—Ö –ì–∞—É—Å—Å",  # —Ç–æ—á–Ω–∞—è —Å—Ç–∞—Ç—å—è
    "Machine Learning",
    ]

# === 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∫–∏–ø–µ–¥–∏–∏ ===
DATASET_DIR = "dataset"
os.makedirs(DATASET_DIR, exist_ok=True)

wiki = wikipediaapi.Wikipedia("en")  # "ru" –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ —Ä—É—Å—Å–∫–∞—è –≤–∏–∫–∏

all_texts = []

def save_page(page, dataset_dir=DATASET_DIR):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ dataset"""
    if not page.exists():
        return False
    safe_name = page.title.replace(" ", "_").replace("/", "_")
    file_path = os.path.join(dataset_dir, f"{safe_name}.txt")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(page.text)
    all_texts.append(page.text)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {file_path} ({len(page.text.split())} —Å–ª–æ–≤)")
    return True

for topic in articles:
    page = wiki.page(topic)
    if page.exists():
        save_page(page)
    else:
        # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –Ω–µ—Ç ‚Üí –∏—â–µ–º –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É
        print(f"üîé –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –ø–æ —Ç–µ–º–µ: {topic}")
        results = wiki.search(topic, results=10)  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —á–∏—Å–ª–æ
        if not results:
            print(f"‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {topic}")
        for r in results:
            p = wiki.page(r)
            save_page(p)

# === 2. –°–æ–±–∏—Ä–∞–µ–º train.txt –∏ eval.txt ===
if all_texts:
    full_text = "\n\n".join(all_texts)
    train_path = "train.txt"
    eval_path = "eval.txt"

    split = int(len(full_text) * 0.9)
    with open(train_path, "w", encoding="utf-8") as f:
        f.write(full_text[:split])
    with open(eval_path, "w", encoding="utf-8") as f:
        f.write(full_text[split:])

    print(f"üìÇ train.txt –∏ eval.txt —Å–æ–∑–¥–∞–Ω—ã (–≤—Å–µ–≥–æ {len(full_text.split())} —Å–ª–æ–≤)")
else:
    raise ValueError("‚ùå –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

# === 3. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∏ –º–æ–¥–µ–ª—å GPT-2 Medium ===
model_name = "gpt2-medium"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token
model = GPT2LMHeadModel.from_pretrained(model_name)

# === 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã ===
def load_dataset(file_path, tokenizer, block_size=512):
    return TextDataset(
        tokenizer=tokenizer,
        file_path=file_path,
        block_size=block_size,
    )

train_dataset = load_dataset(train_path, tokenizer)
eval_dataset = load_dataset(eval_path, tokenizer)

# === 5. Collator ===
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer,
    mlm=False,
)

# === 6. –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è ===
training_args = TrainingArguments(
    output_dir="./gpt2-medium-finetuned",
    overwrite_output_dir=True,
    num_train_epochs=2,  # üî• –Ω–æ—Ä–º –¥–ª—è –≤–∏–∫–∏
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    gradient_accumulation_steps=8,
    evaluation_strategy="steps",
    eval_steps=500,
    save_steps=500,
    logging_steps=100,
    learning_rate=5e-5,
    warmup_steps=200,
    save_total_limit=2,
    fp16=torch.cuda.is_available(),
    report_to="none",

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False,
)

# === 7. Trainer ===
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
)

# === 8. –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ ===
trainer.train()

# === 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç ===
trainer.save_model("./best_model")
tokenizer.save_pretrained("./best_model")

print("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ ./best_model")

